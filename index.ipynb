{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:37.731193Z",
     "start_time": "2023-09-02T13:47:35.912152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./venv/lib/python3.10/site-packages (3.4.1)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./venv/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/02 09:09:46 WARN Utils: Your hostname, Yinkas-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.51 instead (on interface en0)\n",
      "23/09/02 09:09:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/02 09:09:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T15:09:49.472153Z",
     "start_time": "2023-09-02T15:09:43.214755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnull, col"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:37.760590Z",
     "start_time": "2023-09-02T13:47:37.746295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:37.761001Z",
     "start_time": "2023-09-02T13:47:37.754676Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "rows = [('John', 19), ('Paul', 18)]\n",
    "df = spark.createDataFrame(rows, schema='Name string, Age int')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:37.889067Z",
     "start_time": "2023-09-02T13:47:37.764878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:37.890279Z",
     "start_time": "2023-09-02T13:47:37.880407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|John| 19|\n",
      "|Paul| 18|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:39.417638Z",
     "start_time": "2023-09-02T13:47:37.891658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/yinka/PycharmProjects/pythonProject5/result already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1593\u001B[0m, in \u001B[0;36mDataFrameWriter.json\u001B[0;34m(self, path, mode, compression, dateFormat, timestampFormat, lineSep, encoding, ignoreNullFields)\u001B[0m\n\u001B[1;32m   1584\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode(mode)\n\u001B[1;32m   1585\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(\n\u001B[1;32m   1586\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[1;32m   1587\u001B[0m     dateFormat\u001B[38;5;241m=\u001B[39mdateFormat,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1591\u001B[0m     ignoreNullFields\u001B[38;5;241m=\u001B[39mignoreNullFields,\n\u001B[1;32m   1592\u001B[0m )\n\u001B[0;32m-> 1593\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    171\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [PATH_ALREADY_EXISTS] Path file:/Users/yinka/PycharmProjects/pythonProject5/result already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df.write.json('result')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:47:39.659259Z",
     "start_time": "2023-09-02T13:47:39.418343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#read the csv\n",
    "workers_df = spark.read.csv('/Users/yinka/PycharmProjects/pythonProject5/venv/workers.csv', header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:01.773950Z",
     "start_time": "2023-09-02T13:48:01.535403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+---+----------+--------------------+\n",
      "|   name1|     name2|gender|age|  language|          occupation|\n",
      "+--------+----------+------+---+----------+--------------------+\n",
      "| Adolpho|  Pendrich|Female| 21| Norwegian|                null|\n",
      "|    Lief|      Ughi|Female| 22|Portuguese|  Recruiting Manager|\n",
      "|    Alvy|Malatalant|  Male| 24| Malayalam|       VP Accounting|\n",
      "|     Syd|   Daniels|Female| 28|  Moldovan|     Staff Scientist|\n",
      "| Roselin|   Girkins|Female| 35|   Amharic|   Financial Analyst|\n",
      "| Pamella|    Pablos|  Male| 33|  Georgian|  Research Assistant|\n",
      "|  Harmon|Sandercock|  Male| 23|   English|   Marketing Manager|\n",
      "|   Louis| Waterland|Female| 21|    Telugu|Computer Systems ...|\n",
      "| Yehudit|   Oxenden|  Male| 35|   Spanish|  Speech Pathologist|\n",
      "|  Karrie|   Thomsen|  Male| 18|     Tetum|        Statistician|\n",
      "|  Marven| Burchnall|Female| 18|   English| Executive Secretary|\n",
      "|   Nerta|   Kensley|  Male| 19|   Bosnian|               Nurse|\n",
      "|   Piper|   Yarnold|  Male| 21|    Nepali|                null|\n",
      "|  Valene| Foresight|Female| 20|    Kazakh|Accounting Assistant|\n",
      "|Mallorie|   Kelledy|  Male| 30|    German|     Legal Assistant|\n",
      "|    Jase| Devonside|Female| 29|     Dutch|                null|\n",
      "|    Zora|    Jarmyn|Female| 26|    Danish|  Recruiting Manager|\n",
      "|   Sadye|   Millott|Female| 33|     Māori|       Web Developer|\n",
      "|  Dorice|   Glidder|  Male| 21|   English|    Internal Auditor|\n",
      "|   Kelsy|    Sacase|  Male| 23| Icelandic|Senior Financial ...|\n",
      "+--------+----------+------+---+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workers_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:04.289017Z",
     "start_time": "2023-09-02T13:48:04.027591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/02 07:48:09 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+------+-----------------+--------+--------------------+\n",
      "|summary|name1|     name2|gender|              age|language|          occupation|\n",
      "+-------+-----+----------+------+-----------------+--------+--------------------+\n",
      "|  count|   50|        50|    50|               50|      50|                  46|\n",
      "|   mean| null|      null|  null|            25.62|    null|                null|\n",
      "| stddev| null|      null|  null|5.275627441163675|    null|                null|\n",
      "|    min|Abbot|Abramovicz|Female|               18| Amharic|Accounting Assistant|\n",
      "|    max| Zora|   Yarnold|  Male|               35|    Zulu|       Web Developer|\n",
      "+-------+-----+----------+------+-----------------+--------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "workers_df.describe().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:10.311670Z",
     "start_time": "2023-09-02T13:48:08.932782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+---+---------+----------+\n",
      "|  name1|     name2|gender|age| language|occupation|\n",
      "+-------+----------+------+---+---------+----------+\n",
      "|Adolpho|  Pendrich|Female| 21|Norwegian|      null|\n",
      "|  Piper|   Yarnold|  Male| 21|   Nepali|      null|\n",
      "|   Jase| Devonside|Female| 29|    Dutch|      null|\n",
      "|  Leroy|Abramovicz|  Male| 19|   Kazakh|      null|\n",
      "+-------+----------+------+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workers_df.filter(isnull(workers_df.occupation)).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:20.542754Z",
     "start_time": "2023-09-02T13:48:20.339881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+---+----------+--------------------+\n",
      "|   name1|     name2|gender|age|  language|          occupation|\n",
      "+--------+----------+------+---+----------+--------------------+\n",
      "|    Alvy|Malatalant|  Male| 24| Malayalam|       VP Accounting|\n",
      "| Pamella|    Pablos|  Male| 33|  Georgian|  Research Assistant|\n",
      "|  Harmon|Sandercock|  Male| 23|   English|   Marketing Manager|\n",
      "| Yehudit|   Oxenden|  Male| 35|   Spanish|  Speech Pathologist|\n",
      "|  Karrie|   Thomsen|  Male| 18|     Tetum|        Statistician|\n",
      "|   Nerta|   Kensley|  Male| 19|   Bosnian|               Nurse|\n",
      "|   Piper|   Yarnold|  Male| 21|    Nepali|                null|\n",
      "|Mallorie|   Kelledy|  Male| 30|    German|     Legal Assistant|\n",
      "|  Dorice|   Glidder|  Male| 21|   English|    Internal Auditor|\n",
      "|   Kelsy|    Sacase|  Male| 23| Icelandic|Senior Financial ...|\n",
      "|   Lindi|     Gouly|  Male| 28|   Kannada|   Software Engineer|\n",
      "|  Prisca|   Canning|  Male| 32|    Fijian|VP Product Manage...|\n",
      "|   Tadio|      Renn|  Male| 24|     Czech|    Internal Auditor|\n",
      "| Hillyer|   Drought|  Male| 23|   Finnish|  Speech Pathologist|\n",
      "|  Hollie| Buckthorp|  Male| 22| Norwegian|          Programmer|\n",
      "| Shirley|  Orhtmann|  Male| 23|    Korean|           Paralegal|\n",
      "|   Lilla|   Shippam|  Male| 29|   Burmese|        Statistician|\n",
      "|     Roi|   Tarbatt|  Male| 21|  Croatian|           Recruiter|\n",
      "|Emmalynn|   Aspinal|  Male| 32|Lithuanian|       Social Worker|\n",
      "|   Cyndy|       Amy|  Male| 31|  Croatian|GIS Technical Arc...|\n",
      "+--------+----------+------+---+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workers_df.filter(col('gender') == 'Male').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:26.793338Z",
     "start_time": "2023-09-02T13:48:26.604680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "workers_df.filter((col('language').isin('Spanish', 'English')) & (col('age') < 30)).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('name1', 'string'),\n ('name2', 'string'),\n ('gender', 'string'),\n ('age', 'string'),\n ('language', 'string'),\n ('occupation', 'string')]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:42.736427Z",
     "start_time": "2023-09-02T13:48:42.721324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "workers_df = workers_df.withColumn('age', col('age').cast(IntegerType()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:48:57.799941Z",
     "start_time": "2023-09-02T13:48:57.731645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[('name1', 'string'),\n ('name2', 'string'),\n ('gender', 'string'),\n ('age', 'int'),\n ('language', 'string'),\n ('occupation', 'string')]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:00.529723Z",
     "start_time": "2023-09-02T13:49:00.512779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "workers_df = workers_df.withColumnsRenamed({'name1': 'firstname', 'name2': 'lastname'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:14.062697Z",
     "start_time": "2023-09-02T13:49:14.044109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "workers_df = workers_df.na.fill('Not Provided')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:17.513500Z",
     "start_time": "2023-09-02T13:49:17.489073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+---+----------+--------------------+\n",
      "|firstname|  lastname|gender|age|  language|          occupation|\n",
      "+---------+----------+------+---+----------+--------------------+\n",
      "|  Adolpho|  Pendrich|Female| 21| Norwegian|        Not Provided|\n",
      "|     Lief|      Ughi|Female| 22|Portuguese|  Recruiting Manager|\n",
      "|     Alvy|Malatalant|  Male| 24| Malayalam|       VP Accounting|\n",
      "|      Syd|   Daniels|Female| 28|  Moldovan|     Staff Scientist|\n",
      "|  Roselin|   Girkins|Female| 35|   Amharic|   Financial Analyst|\n",
      "|  Pamella|    Pablos|  Male| 33|  Georgian|  Research Assistant|\n",
      "|   Harmon|Sandercock|  Male| 23|   English|   Marketing Manager|\n",
      "|    Louis| Waterland|Female| 21|    Telugu|Computer Systems ...|\n",
      "|  Yehudit|   Oxenden|  Male| 35|   Spanish|  Speech Pathologist|\n",
      "|   Karrie|   Thomsen|  Male| 18|     Tetum|        Statistician|\n",
      "|   Marven| Burchnall|Female| 18|   English| Executive Secretary|\n",
      "|    Nerta|   Kensley|  Male| 19|   Bosnian|               Nurse|\n",
      "|    Piper|   Yarnold|  Male| 21|    Nepali|        Not Provided|\n",
      "|   Valene| Foresight|Female| 20|    Kazakh|Accounting Assistant|\n",
      "| Mallorie|   Kelledy|  Male| 30|    German|     Legal Assistant|\n",
      "|     Jase| Devonside|Female| 29|     Dutch|        Not Provided|\n",
      "|     Zora|    Jarmyn|Female| 26|    Danish|  Recruiting Manager|\n",
      "|    Sadye|   Millott|Female| 33|     Māori|       Web Developer|\n",
      "|   Dorice|   Glidder|  Male| 21|   English|    Internal Auditor|\n",
      "|    Kelsy|    Sacase|  Male| 23| Icelandic|Senior Financial ...|\n",
      "+---------+----------+------+---+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using sql\n",
    "workers_df.createOrReplaceTempView('workers')\n",
    "spark.sql('SELECT * FROM workers').show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:24.876198Z",
     "start_time": "2023-09-02T13:49:24.670691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|  language|total_speakers|\n",
      "+----------+--------------+\n",
      "|   English|             5|\n",
      "|  Croatian|             3|\n",
      "|    Kazakh|             3|\n",
      "|Portuguese|             2|\n",
      "| Norwegian|             2|\n",
      "|   Amharic|             2|\n",
      "|    Fijian|             1|\n",
      "|Papiamento|             1|\n",
      "|    Nepali|             1|\n",
      "|   Kannada|             1|\n",
      "|   Finnish|             1|\n",
      "|     Tetum|             1|\n",
      "| Icelandic|             1|\n",
      "|  Assamese|             1|\n",
      "|   Bosnian|             1|\n",
      "|   Guaraní|             1|\n",
      "|    Telugu|             1|\n",
      "|  Filipino|             1|\n",
      "|     Azeri|             1|\n",
      "|   Spanish|             1|\n",
      "+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT language, COUNT(firstname) AS total_speakers FROM workers GROUP BY language ORDER BY total_speakers DESC\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:33.579779Z",
     "start_time": "2023-09-02T13:49:32.917966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT CONCAT(firstname, \" \", lastname) AS fullname, date_sub(curdate(), (age * 365)) AS DOB, * FROM workers\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:37.782124Z",
     "start_time": "2023-09-02T13:49:37.740191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "workers_df = spark.sql(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:40.345506Z",
     "start_time": "2023-09-02T13:49:40.311873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+---------+----------+------+---+----------+--------------------+\n",
      "|         fullname|       DOB|firstname|  lastname|gender|age|  language|          occupation|\n",
      "+-----------------+----------+---------+----------+------+---+----------+--------------------+\n",
      "| Adolpho Pendrich|2002-09-07|  Adolpho|  Pendrich|Female| 21| Norwegian|        Not Provided|\n",
      "|        Lief Ughi|2001-09-07|     Lief|      Ughi|Female| 22|Portuguese|  Recruiting Manager|\n",
      "|  Alvy Malatalant|1999-09-08|     Alvy|Malatalant|  Male| 24| Malayalam|       VP Accounting|\n",
      "|      Syd Daniels|1995-09-09|      Syd|   Daniels|Female| 28|  Moldovan|     Staff Scientist|\n",
      "|  Roselin Girkins|1988-09-10|  Roselin|   Girkins|Female| 35|   Amharic|   Financial Analyst|\n",
      "|   Pamella Pablos|1990-09-10|  Pamella|    Pablos|  Male| 33|  Georgian|  Research Assistant|\n",
      "|Harmon Sandercock|2000-09-07|   Harmon|Sandercock|  Male| 23|   English|   Marketing Manager|\n",
      "|  Louis Waterland|2002-09-07|    Louis| Waterland|Female| 21|    Telugu|Computer Systems ...|\n",
      "|  Yehudit Oxenden|1988-09-10|  Yehudit|   Oxenden|  Male| 35|   Spanish|  Speech Pathologist|\n",
      "|   Karrie Thomsen|2005-09-06|   Karrie|   Thomsen|  Male| 18|     Tetum|        Statistician|\n",
      "| Marven Burchnall|2005-09-06|   Marven| Burchnall|Female| 18|   English| Executive Secretary|\n",
      "|    Nerta Kensley|2004-09-06|    Nerta|   Kensley|  Male| 19|   Bosnian|               Nurse|\n",
      "|    Piper Yarnold|2002-09-07|    Piper|   Yarnold|  Male| 21|    Nepali|        Not Provided|\n",
      "| Valene Foresight|2003-09-07|   Valene| Foresight|Female| 20|    Kazakh|Accounting Assistant|\n",
      "| Mallorie Kelledy|1993-09-09| Mallorie|   Kelledy|  Male| 30|    German|     Legal Assistant|\n",
      "|   Jase Devonside|1994-09-09|     Jase| Devonside|Female| 29|     Dutch|        Not Provided|\n",
      "|      Zora Jarmyn|1997-09-08|     Zora|    Jarmyn|Female| 26|    Danish|  Recruiting Manager|\n",
      "|    Sadye Millott|1990-09-10|    Sadye|   Millott|Female| 33|     Māori|       Web Developer|\n",
      "|   Dorice Glidder|2002-09-07|   Dorice|   Glidder|  Male| 21|   English|    Internal Auditor|\n",
      "|     Kelsy Sacase|2000-09-07|    Kelsy|    Sacase|  Male| 23| Icelandic|Senior Financial ...|\n",
      "+-----------------+----------+---------+----------+------+---+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workers_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:41.329296Z",
     "start_time": "2023-09-02T13:49:41.173443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[fullname: string, gender: string, age: int, language: string, occupation: string, DOB: date]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers_df.select(['fullname', 'gender', 'age', 'language', 'occupation', 'DOB'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:50.571648Z",
     "start_time": "2023-09-02T13:49:50.478518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "workers_df.write.option('header', True).partitionBy(['language', 'gender']).mode('overwrite').format('csv').save('result')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:49:54.096737Z",
     "start_time": "2023-09-02T13:49:52.279946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT CONCAT(firstname, \" \", lastname) AS fullname, date_sub(curdate(), (age * 365)) AS DOB, * ,year(date_sub(curdate(), (age * 365))) AS YearOfBirth FROM workers\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:50:05.786096Z",
     "start_time": "2023-09-02T13:50:05.775147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `YearOfBirth` cannot be resolved. Did you mean one of the following? [`DOB`, `workers`.`age`, `fullname`, `workers`.`firstname`, `workers`.`gender`].;\n'Project [fullname#731, gender#669, age#646, language#670, occupation#671, DOB#732, 'YearOfBirth]\n+- Project [concat(firstname#667,  , lastname#668) AS fullname#731, date_sub(current_date(Some(America/Regina)), (age#646 * 365)) AS DOB#732, firstname#667, lastname#668, gender#669, age#646, language#670, occupation#671]\n   +- SubqueryAlias workers\n      +- View (`workers`, [firstname#667,lastname#668,gender#669,age#646,language#670,occupation#671])\n         +- Project [coalesce(firstname#654, cast(Not Provided as string)) AS firstname#667, coalesce(lastname#653, cast(Not Provided as string)) AS lastname#668, coalesce(gender#65, cast(Not Provided as string)) AS gender#669, age#646, coalesce(language#67, cast(Not Provided as string)) AS language#670, coalesce(occupation#68, cast(Not Provided as string)) AS occupation#671]\n            +- Project [name1#63 AS firstname#654, name2#64 AS lastname#653, gender#65, age#646, language#67, occupation#68]\n               +- Project [name1#63, name2#64, gender#65, cast(age#66 as int) AS age#646, language#67, occupation#68]\n                  +- Relation [name1#63,name2#64,gender#65,age#66,language#67,occupation#68] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mworkers_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfullname\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgender\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlanguage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moccupation\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDOB\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mYearOfBirth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3036\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2991\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2992\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2993\u001B[0m \n\u001B[1;32m   2994\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3034\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n\u001B[1;32m   3035\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3036\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3037\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject5/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    171\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `YearOfBirth` cannot be resolved. Did you mean one of the following? [`DOB`, `workers`.`age`, `fullname`, `workers`.`firstname`, `workers`.`gender`].;\n'Project [fullname#731, gender#669, age#646, language#670, occupation#671, DOB#732, 'YearOfBirth]\n+- Project [concat(firstname#667,  , lastname#668) AS fullname#731, date_sub(current_date(Some(America/Regina)), (age#646 * 365)) AS DOB#732, firstname#667, lastname#668, gender#669, age#646, language#670, occupation#671]\n   +- SubqueryAlias workers\n      +- View (`workers`, [firstname#667,lastname#668,gender#669,age#646,language#670,occupation#671])\n         +- Project [coalesce(firstname#654, cast(Not Provided as string)) AS firstname#667, coalesce(lastname#653, cast(Not Provided as string)) AS lastname#668, coalesce(gender#65, cast(Not Provided as string)) AS gender#669, age#646, coalesce(language#67, cast(Not Provided as string)) AS language#670, coalesce(occupation#68, cast(Not Provided as string)) AS occupation#671]\n            +- Project [name1#63 AS firstname#654, name2#64 AS lastname#653, gender#65, age#646, language#67, occupation#68]\n               +- Project [name1#63, name2#64, gender#65, cast(age#66 as int) AS age#646, language#67, occupation#68]\n                  +- Relation [name1#63,name2#64,gender#65,age#66,language#67,occupation#68] csv\n"
     ]
    }
   ],
   "source": [
    "workers_df.select(['fullname', 'gender', 'age', 'language', 'occupation', 'DOB', 'YearOfBirth']).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T13:50:07.199144Z",
     "start_time": "2023-09-02T13:50:06.938121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
